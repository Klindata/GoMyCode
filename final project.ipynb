{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. DATASET PRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A. <u>Loading</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 4238 rows and 16 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B) <u>Source</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The dataset is publically available on the Kaggle website, and it is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts.</p>\n",
    "<p>The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).</p>\n",
    "<p>The dataset provides the patientsâ€™ information. Each variable represents a potential risk factor of contracting a coronary heart disease. There are both socio-demographic and medical risk factors.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C) <u>Features</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['sex', 'age', 'education', 'smoker', 'cigs_per_day', 'bp_meds', 'prev_stroke', 'prev_hyp', 'diabetes', 'level_chol', 'bp_sys', 'bp_dias', 'bmi', 'heart_rate', 'level_gluc', 'ten_year_risk_chd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_presentation = pd.DataFrame(\n",
    "    \n",
    "{\"Variables\": data.columns, \n",
    " \n",
    "\"Description\": \n",
    "[\"0 : Female ; 1 : Male\",\n",
    "\"Age at exam time\",\n",
    "\"1 : Some High School ; 2 : High School or GED ; 3 : Some College or Vocational School ; 4 : College\",\n",
    "\"0 : Non-current smoker ; 1: Current smoker\",\n",
    "\"Number of cigarettes smoked per day (estimated average)\",\n",
    "\"0 : Not on Blood Pressure medications ; 1 : Is on Blood Pressure medications\",\n",
    "\"0 : No prevalent stroke ; 1 : Prevalent stroke(s)\",\n",
    "\"0 : No prevalent hypertension ; 1 : Prevalent hypertension\",\n",
    "\"0 : Non-diabetic patient ; 1 : diabetic patient\",\n",
    "\"Total cholesterol level (mg/dL)\",\n",
    "\"Systolic blood pressure (mmHg)\",\n",
    "\"Diastolic blood pressure (mmHg)\", \n",
    "\"Body Mass Index (calculated as: Weight(kg) / Height(meter-squared))\", \n",
    "\"Heart rate (beats per minute)\",\n",
    "\"Glucose level (mg/dL)\",\n",
    "\"10-year risk of coronary heart disease (0 : no ; 1 : yes)\"],\n",
    "\n",
    "\"Risk Factor Category\": [\"Socio-Demographic\", \"Socio-Demographic\", \"Socio-Demographic\", \"Socio-Demographic\", \"Behavioral\", \"Medical (history)\", \"Medical (history)\", \"Medical (history)\", \"Medical (history)\", \"Medical (measures)\", \"Medical (measures)\", \"Medical (measures)\", \"Medical (measures)\", \"Medical (measures)\", \"Medical (measures)\", \"Risk Prediction\"], \n",
    "\n",
    "\"Variable Type\": [\"Nominal\", \"Continuous\", \"Nominal\", \"Nominal\", \"Continuous\", \"Nominal\", \"Nominal\", \"Nominal\", \"Nominal\", \"Continuous\", \"Continuous\", \"Continuous\", \"Continuous\", \"Continuous\", \"Continuous\", \"Target : Nominal\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "features_presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A) <u>Missing values</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Education column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_education = data['education'].mode()\n",
    "mode_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['education'].fillna(mode_education[0], inplace=True)\n",
    "data['education'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cigs_per_day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cigs_per_day = data[data['smoker']==1]['cigs_per_day'].median()\n",
    "median_cigs_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cigs_per_day'].fillna(median_cigs_per_day, inplace=True)\n",
    "data['cigs_per_day'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BP medication column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_bp_meds = data['bp_meds'].mode()\n",
    "mode_bp_meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bp_meds'].fillna(mode_bp_meds[0], inplace=True)\n",
    "data['bp_meds'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Level cholesterol column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_level_chol = data['level_chol'].mean()\n",
    "mean_level_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['level_chol'].fillna(mean_level_chol, inplace=True)\n",
    "data['level_chol'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BMI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bmi = data['bmi'].mean()\n",
    "mean_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bmi'].fillna(mean_bmi, inplace=True)\n",
    "data['bmi'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Heart rate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_heart_rate = data['heart_rate'].mean()\n",
    "mean_heart_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['heart_rate'].fillna(mean_heart_rate, inplace=True)\n",
    "data['heart_rate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Level glucose column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_level_gluc = data['level_gluc'].mean()\n",
    "mean_level_gluc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['level_gluc'].fillna(mean_level_gluc, inplace=True)\n",
    "data['level_gluc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B) <u>Feature engineering</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Variables 'smoker' and 'cigs_per_day' are redundant.</p>\n",
    "<p>We can create a multi-level categorical variable 'tobacco' where:</p>\n",
    "\n",
    "- 0 for non_smokers \n",
    "- 1 for light smokers (cigs_per_day <= 20)\n",
    "- 2 for heavy smokers (cigs_per_day > 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoker(row):\n",
    "    if row['cigs_per_day'] == 0:\n",
    "        return 0\n",
    "    elif row['cigs_per_day'] <= 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "data['tobacco'] = data.apply(lambda row: smoker(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tobacco'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['smoker','cigs_per_day'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C) <u>Reorder columns</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socio_demographic_vars = ['sex', 'age', 'education', 'tobacco']\n",
    "med_history_vars = ['bp_meds', 'prev_stroke', 'prev_hyp', 'diabetes']\n",
    "med_measures_vars = ['bmi', 'heart_rate', 'level_gluc', 'level_chol', 'bp_sys', 'bp_dias']\n",
    "prediction_var = ['ten_year_risk_chd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = socio_demographic_vars + med_history_vars + med_measures_vars + prediction_var\n",
    "data = data[new_order]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A) <u>Summary statistics</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B) <u>Profiling report</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "data.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C) <u>Distribution of Target Variable : 10-year risk CHD</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = data['ten_year_risk_chd'].value_counts()\n",
    "print('Patients not a risk:', target_count[0])\n",
    "print('Patients at risk:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=(15,8))\n",
    "\n",
    "ax1 = target_count.plot(kind='pie', startangle=60, autopct='%1.1f%%', labels=[\"Not at risk\",\"At risk\"], colors=['forestgreen', 'firebrick'], ax=ax1)\n",
    "ax1.set(title = 'Percentage of patients at risk CHD')\n",
    "\n",
    "\n",
    "ax2 = sns.countplot(x=data['ten_year_risk_chd'], palette=['forestgreen', 'firebrick'], ax=ax2)\n",
    "ax2.set(xlabel='Risk CHD No / Yes', ylabel='Count', title='Count of patients according to risk CHD')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The dataset has clearly an imbalanced distribution.<br>\n",
    "Indeed, observations in the class 0 (patients not at risk) are much higher than the observations in the class 1 (patients at risk).<br>\n",
    "The ratio is 1 to 5.5. <br>\n",
    "There are techniques for handling imbalanced datasets : the 'SMOTE algorithm' for example (see \"Part 3. Model Preparation\")</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>D) <u>Socio-Demographic Variables</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax = sns.countplot(x=data['age'], hue=data['ten_year_risk_chd'], palette=['forestgreen', 'firebrick'])\n",
    "ax.set(xlabel='Age', ylabel='Count', title='Age vs Risk CHD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(8,12))\n",
    "plt.subplot(211)\n",
    "data['sex'].value_counts().plot(kind='pie', startangle=90, autopct='%1.1f%%', colors=['pink', 'lightblue'], labels=['Female', 'Male'])\n",
    "plt.title('Sex distribution')\n",
    "plt.subplot(212)\n",
    "sns.countplot(x=data['sex'], hue=data['ten_year_risk_chd'], palette=['forestgreen', 'firebrick']) \n",
    "plt.xlabel('Sex : 0=Female ; 1=Male')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Risk CHD by Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(8,12))\n",
    "plt.subplot(211)\n",
    "data['education'].value_counts().plot(kind='pie', startangle=90, autopct='%1.1f%%', colors=['lemonchiffon', 'khaki', 'gold', 'goldenrod'], labels=['1: Some High School', '2: GED', '3: Some College', '4: College Graduate'])\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Education levels')\n",
    "plt.subplot(212)\n",
    "sns.countplot(x=data['education'], hue=data['ten_year_risk_chd'], palette=['forestgreen', 'firebrick']) \n",
    "plt.xlabel('Education level')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Risk CHD by Education level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no correlation between the level of education and the risk to contract a CHD.<br>\n",
    "The coefficient of correlation is very low : -0.05<br>\n",
    "Therefore we can drop the 'education' column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tobacco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(8,12))\n",
    "plt.subplot(211)\n",
    "data['tobacco'].value_counts().plot(kind='pie', startangle=90, autopct='%1.1f%%', colors=[\"bisque\", \"chocolate\", \"saddlebrown\"], labels=['0: No smoker', '1: Light Smoker', '3: Heavy smoker'])\n",
    "plt.ylabel('')\n",
    "plt.title('Smoking variable distribution')\n",
    "plt.subplot(212)\n",
    "sns.countplot(x=data['tobacco'], hue=data['ten_year_risk_chd'], palette=['forestgreen', 'firebrick']) \n",
    "plt.xlabel('Tobacco')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Risk CHD by Tobacco consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>E) <u>Medical Variables</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Medical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.boxplot(data = data[med_measures_vars])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr()\n",
    "correlation['ten_year_risk_chd'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "sns.heatmap(correlation, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A) <u>Feature scaling using 'StandardScaler'</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['ten_year_risk_chd'], axis=1)\n",
    "y = data['ten_year_risk_chd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B) <u>Splitting data (using 'train_test_split')</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(X_train) =\", len(X_train))\n",
    "print(\"len(X_test) =\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C) <u>Resampling imbalanced dataset (using SMOTE algorithm)</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem.\n",
    "It aims to balance class distribution by randomly increasing minority class examples by replicating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of risk_CDH = 0 :\", sum(y_train==0))\n",
    "print(\"Before OverSampling, counts of risk_CDH = 1 :\", sum(y_train==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After OverSampling, counts of risk_CDH = 0 :\", sum(y_train==0))\n",
    "print(\"After OverSampling, counts of risk_CDH = 1 :\", sum(y_train==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>SMOTE Algorithm has oversampled the minority instances (risk_CHD = 1) and made it equal to majority class (risk_CHD = 0).</p>\n",
    "<p>Now, both categories have equal amount of records (2686).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithms that we will be used are :\n",
    "\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Random Forest Classification\n",
    "- Support Vector Machine\n",
    "- Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A) <u>Logistic Regression</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "y_pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_logr = confusion_matrix(y_test, y_pred)\n",
    "cm_logr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logr = accuracy_score(y_test, y_pred)\n",
    "recall_logr = recall_score(y_test, y_pred)\n",
    "precision_logr = precision_score(y_test, y_pred)\n",
    "f1_logr = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy Score: \", acc_logr)\n",
    "print(\"Recall Score: \", recall_logr)\n",
    "print(\"Precision Score: \", precision_logr)\n",
    "print(\"F1 Score: \", f1_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logr.predict_proba(X_test)[:,1]\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], '--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>B) <u>K-Nearest Neighbors</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find optimal 'k' (number of neighbors)\n",
    "\n",
    "def KNeighbors(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for i in range(1,20):\n",
    "        KN = KNeighborsClassifier(n_neighbors=i)\n",
    "        KN.fit(X_train, y_train)\n",
    "        y_pred2 = KN.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_pred2, y_test))\n",
    "    \n",
    "    max_score = max(accuracy_scores)\n",
    "    optimal_k = accuracy_scores.index(max_score) + 1\n",
    "    \n",
    "    print(f\"The best accuracy score for KNN model is: {max_score} when n_neighbors = {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighbors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred2 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn = confusion_matrix(y_pred2, y_test)\n",
    "cm_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knn = accuracy_score(y_test, y_pred2)\n",
    "print(\"Accuracy Score: \", accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred2, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C) <u>Decision tree</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fix the maximum number of lead nodes (pruning)\n",
    "\n",
    "def pruning(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for i in range(2,20):\n",
    "        dt = DecisionTreeClassifier(max_leaf_nodes=i)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred3 = dt.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_pred3, y_test))\n",
    "    \n",
    "    max_score = max(accuracy_scores)\n",
    "    nodes = accuracy_scores.index(max_score) + 2\n",
    "    print(f\"The best accuracy score for decision tree classifier is: {max_score} when max_leaf_nodes = {nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(max_leaf_nodes = 17)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred3 = decision_tree.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plot_tree(decision_tree, filled = True, feature_names = X.columns, proportion = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_tree = confusion_matrix(y_pred3, y_test)\n",
    "cm_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_decision_tree = accuracy_score(y_test, y_pred3)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred3, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>D) <u>Random Forest</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for i in range(1,1000):\n",
    "        rf = RandomForestClassifier(n_estimators=i)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred3 = rf.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_pred3, y_test))\n",
    "    \n",
    "    max_score = max(accuracy_scores)\n",
    "    estimators = accuracy_scores.index(max_score) + 2\n",
    "    print(f\"The best accuracy score for decision tree classifier is: {max_score} when max_leaf_nodes = {estimators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_forest = confusion_matrix(y_pred4, y_test)\n",
    "cm_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_accuracy = accuracy_score(y_pred4, y_test)\n",
    "forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred4, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>E) <u>Support Vector Machine</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel= 'rbf', max_iter=10000, C=1.0, gamma='auto')\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred5 = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svc = confusion_matrix(y_pred5, y_test)\n",
    "cm_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_accuracy = accuracy_score(y_pred5, y_test)\n",
    "svc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred5, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>F) <u>Naive Bayes</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "y_pred6 = naive_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nb = confusion_matrix(y_pred6, y_test)\n",
    "cm_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_accuracy = accuracy_score(y_pred6, y_test)\n",
    "nb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred6, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model':['Logistic Regression','KNN','Decision Tree','SVM','Random Forest','Naive Bayes'],\n",
    "        'F1 Score':[6.60,12.5,22.7,1.70,13.0,26.0],'Accuracies':[84.89,84.1,74.1,84.7,83.89,81.8],'Recall':[3.40,7.30,24.6,0.89,7.80,20.70],'Precision':[72.70,41.50,21.00,100.00,40.00,35.00]}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "# Print the output.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.barplot(x='Model', y='Accuracies', data = df)\n",
    "plt.title('Comparison of accuracy of models')\n",
    "plt.xlabel('model algorithms', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = ['Logistic Regression','KNN','Decision Tree','Random Forest','SVC', 'Naives Bayes', 'Extreme Gradient Boost']\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "         KNeighborsClassifier(n_neighbors = 14),\n",
    "         DecisionTreeClassifier(max_leaf_nodes = 2),\n",
    "         RandomForestClassifier(n_estimators= 5000, random_state= 42),\n",
    "         SVC(kernel= 'rbf', max_iter=10000, C=1.0, gamma='auto'),\n",
    "         GaussianNB(), \n",
    "         ]\n",
    "\n",
    "for n, mod in zip(names, models):\n",
    "    \n",
    "    mod.fit(X_train, y_train) \n",
    "    print(f\"Accuracy {n}: {round((mod.score(X_test, y_test)) *100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=cross_val_score(LogisticRegression(),imputed_data.drop('TenYearCHD',axis=1),imputed_data['TenYearCHD'],cv=10)\n",
    "print(f\"After k-fold cross validation score is {score.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingCVClassifier(classifiers=[xgb,knn,svc],meta_classifier= svc,random_state=42)\n",
    "scv.fit(X_train,y_train)\n",
    "scv_predicted = scv.predict(X_test)\n",
    "scv_conf_matrix = confusion_matrix(y_test, scv_predicted)\n",
    "scv_acc_score = accuracy_score(y_test, scv_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(scv_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of StackingCVClassifier:\",scv_acc_score*100,'\\n')\n",
    "print(classification_report(y_test,scv_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
